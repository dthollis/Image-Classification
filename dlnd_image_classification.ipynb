{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f801c7df908>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    return x / np.linalg.norm(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "isEncoded = False\n",
    "encode = LabelBinarizer()\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    global isEncoded\n",
    "    \n",
    "    if not isEncoded:\n",
    "        encode.fit(x)\n",
    "        isEncoded = True\n",
    "        \n",
    "    return encode.transform(x)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    weight = tf.Variable(tf.truncated_normal([*conv_ksize, x_tensor.get_shape().as_list()[3], conv_num_outputs], mean=0, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    \n",
    "    x_tensor = tf.nn.conv2d(x_tensor, weight, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, bias)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    x_tensor = tf.nn.max_pool(x_tensor, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "    \n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    dim = tf.Variable(tf.truncated_normal([int(x_tensor.shape[1]*x_tensor.shape[2]*x_tensor.shape[3])], mean=0, stddev=0.1))\n",
    "    \n",
    "    return tf.reshape(x_tensor, [-1, dim.get_shape().as_list()[0]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    weight = tf.Variable(tf.truncated_normal([int(x_tensor.shape[1]), num_outputs], mean=0, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    \n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    weight = tf.Variable(tf.truncated_normal([int(x_tensor.shape[1]), num_outputs], mean=0, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    \n",
    "    out = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    conv_ksize = (5, 5)\n",
    "    conv_strides = (1, 1)\n",
    "    pool_ksize = (2, 2)\n",
    "    pool_strides = (2, 2)\n",
    "    \n",
    "    # Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    x1 = conv2d_maxpool(x, 32, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    x2 = conv2d_maxpool(x1, 48, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # Function Definition from Above:\n",
    "    fc = flatten(x2)\n",
    "\n",
    "    # Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    fc1 = fully_conn(fc, 1024)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    # Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    out = output(fc1, 10)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: keep_probability})\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.})\n",
    "    \n",
    "    valid_acc = session.run(accuracy, feed_dict={\n",
    "        x: valid_features,\n",
    "        y: valid_labels,\n",
    "        keep_prob: 1.})\n",
    "\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "        loss,\n",
    "        valid_acc))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 464\n",
    "batch_size = 256\n",
    "keep_probability = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3024 Validation Accuracy: 0.102000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3029 Validation Accuracy: 0.105000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.3026 Validation Accuracy: 0.102000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.3024 Validation Accuracy: 0.105000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.3029 Validation Accuracy: 0.121200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.3019 Validation Accuracy: 0.116200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.2880 Validation Accuracy: 0.172800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.2133 Validation Accuracy: 0.203400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.2056 Validation Accuracy: 0.208200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.1903 Validation Accuracy: 0.216000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.1763 Validation Accuracy: 0.210800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     2.1546 Validation Accuracy: 0.220200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     2.1306 Validation Accuracy: 0.221000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     2.1012 Validation Accuracy: 0.242000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     2.0625 Validation Accuracy: 0.241800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     2.0339 Validation Accuracy: 0.248000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.9985 Validation Accuracy: 0.246400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.9597 Validation Accuracy: 0.261800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.9322 Validation Accuracy: 0.261200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.9042 Validation Accuracy: 0.272800\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.8650 Validation Accuracy: 0.275400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.8361 Validation Accuracy: 0.276800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.8056 Validation Accuracy: 0.288600\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.7722 Validation Accuracy: 0.285400\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.7486 Validation Accuracy: 0.293800\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.7167 Validation Accuracy: 0.297600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.7006 Validation Accuracy: 0.320200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.6694 Validation Accuracy: 0.320200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.6506 Validation Accuracy: 0.329200\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.6323 Validation Accuracy: 0.318000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.6070 Validation Accuracy: 0.327800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.5901 Validation Accuracy: 0.326600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.5691 Validation Accuracy: 0.337200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.5477 Validation Accuracy: 0.334800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.5382 Validation Accuracy: 0.338600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.5171 Validation Accuracy: 0.335800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.5029 Validation Accuracy: 0.340600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.4902 Validation Accuracy: 0.339000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.4863 Validation Accuracy: 0.338400\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.4671 Validation Accuracy: 0.346000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.4472 Validation Accuracy: 0.341200\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.4265 Validation Accuracy: 0.345200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.4217 Validation Accuracy: 0.344200\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.3871 Validation Accuracy: 0.349800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.3708 Validation Accuracy: 0.345200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.3653 Validation Accuracy: 0.350600\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.3489 Validation Accuracy: 0.349400\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.3216 Validation Accuracy: 0.347000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.3172 Validation Accuracy: 0.348000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.3095 Validation Accuracy: 0.355800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.3002 Validation Accuracy: 0.348000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.2903 Validation Accuracy: 0.356600\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.2735 Validation Accuracy: 0.355800\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.2555 Validation Accuracy: 0.356400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.2504 Validation Accuracy: 0.357400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.2214 Validation Accuracy: 0.358800\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.2247 Validation Accuracy: 0.354000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.1991 Validation Accuracy: 0.356600\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.1733 Validation Accuracy: 0.359200\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.1673 Validation Accuracy: 0.354000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.1593 Validation Accuracy: 0.356200\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.1374 Validation Accuracy: 0.364000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.1236 Validation Accuracy: 0.359600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.1234 Validation Accuracy: 0.359400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.1033 Validation Accuracy: 0.362000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.0875 Validation Accuracy: 0.365600\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.0840 Validation Accuracy: 0.365400\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.0732 Validation Accuracy: 0.366600\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.0668 Validation Accuracy: 0.366200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.0453 Validation Accuracy: 0.367200\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.0383 Validation Accuracy: 0.369200\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.0217 Validation Accuracy: 0.367800\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.0131 Validation Accuracy: 0.372000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     0.9944 Validation Accuracy: 0.366600\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     0.9822 Validation Accuracy: 0.366600\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     0.9710 Validation Accuracy: 0.370200\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     0.9546 Validation Accuracy: 0.371600\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     0.9401 Validation Accuracy: 0.372600\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     0.9464 Validation Accuracy: 0.372000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     0.9364 Validation Accuracy: 0.364400\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     0.9263 Validation Accuracy: 0.374400\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     0.9048 Validation Accuracy: 0.375000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     0.8959 Validation Accuracy: 0.374400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     0.8808 Validation Accuracy: 0.376800\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     0.8698 Validation Accuracy: 0.372800\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     0.8744 Validation Accuracy: 0.374000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     0.8433 Validation Accuracy: 0.376800\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     0.8352 Validation Accuracy: 0.377800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     0.8201 Validation Accuracy: 0.377800\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     0.8161 Validation Accuracy: 0.376000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     0.8056 Validation Accuracy: 0.377600\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     0.7711 Validation Accuracy: 0.382200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     0.7700 Validation Accuracy: 0.383200\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     0.7759 Validation Accuracy: 0.385400\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     0.7468 Validation Accuracy: 0.380000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     0.7417 Validation Accuracy: 0.384800\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     0.7358 Validation Accuracy: 0.385200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     0.7309 Validation Accuracy: 0.383600\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     0.7285 Validation Accuracy: 0.382800\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     0.6919 Validation Accuracy: 0.390400\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     0.6987 Validation Accuracy: 0.383600\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     0.6837 Validation Accuracy: 0.384800\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     0.6931 Validation Accuracy: 0.385200\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     0.6685 Validation Accuracy: 0.391400\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     0.6486 Validation Accuracy: 0.390600\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     0.6330 Validation Accuracy: 0.390400\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     0.6283 Validation Accuracy: 0.393000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     0.6040 Validation Accuracy: 0.394400\n",
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     0.6234 Validation Accuracy: 0.391800\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     0.6098 Validation Accuracy: 0.386600\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     0.6015 Validation Accuracy: 0.396000\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     0.6033 Validation Accuracy: 0.388600\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     0.5797 Validation Accuracy: 0.389800\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     0.5699 Validation Accuracy: 0.395200\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     0.5702 Validation Accuracy: 0.398000\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     0.5615 Validation Accuracy: 0.399400\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     0.5658 Validation Accuracy: 0.395400\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     0.5446 Validation Accuracy: 0.397400\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     0.5425 Validation Accuracy: 0.404600\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     0.5218 Validation Accuracy: 0.406000\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     0.5309 Validation Accuracy: 0.403200\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     0.5152 Validation Accuracy: 0.403800\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     0.5124 Validation Accuracy: 0.400800\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     0.5032 Validation Accuracy: 0.399600\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     0.5035 Validation Accuracy: 0.408600\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     0.4847 Validation Accuracy: 0.404200\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     0.4663 Validation Accuracy: 0.402400\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     0.4725 Validation Accuracy: 0.405400\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     0.4665 Validation Accuracy: 0.403400\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     0.4650 Validation Accuracy: 0.401200\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     0.4479 Validation Accuracy: 0.398200\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     0.4593 Validation Accuracy: 0.395000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     0.4398 Validation Accuracy: 0.398200\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     0.4462 Validation Accuracy: 0.398400\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     0.4369 Validation Accuracy: 0.395000\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     0.4498 Validation Accuracy: 0.401200\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     0.4388 Validation Accuracy: 0.394000\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     0.4225 Validation Accuracy: 0.398600\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     0.4241 Validation Accuracy: 0.407400\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     0.4336 Validation Accuracy: 0.395600\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     0.4100 Validation Accuracy: 0.397000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     0.4042 Validation Accuracy: 0.402200\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     0.4086 Validation Accuracy: 0.404800\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     0.3999 Validation Accuracy: 0.401600\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     0.3806 Validation Accuracy: 0.407000\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     0.3859 Validation Accuracy: 0.405800\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     0.3713 Validation Accuracy: 0.410800\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     0.3837 Validation Accuracy: 0.401400\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     0.3803 Validation Accuracy: 0.401200\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     0.3656 Validation Accuracy: 0.409600\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     0.3751 Validation Accuracy: 0.405600\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     0.3919 Validation Accuracy: 0.395000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     0.3620 Validation Accuracy: 0.407800\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     0.3706 Validation Accuracy: 0.405000\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     0.3706 Validation Accuracy: 0.402600\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     0.3705 Validation Accuracy: 0.408200\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     0.3688 Validation Accuracy: 0.411400\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     0.3448 Validation Accuracy: 0.418200\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     0.3628 Validation Accuracy: 0.415800\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     0.3475 Validation Accuracy: 0.422600\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     0.3402 Validation Accuracy: 0.425200\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     0.3320 Validation Accuracy: 0.431200\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     0.3430 Validation Accuracy: 0.420200\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     0.3498 Validation Accuracy: 0.428800\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     0.3334 Validation Accuracy: 0.414000\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     0.3226 Validation Accuracy: 0.421800\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     0.3400 Validation Accuracy: 0.422000\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     0.3233 Validation Accuracy: 0.427400\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     0.3104 Validation Accuracy: 0.429800\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     0.3208 Validation Accuracy: 0.426000\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     0.3097 Validation Accuracy: 0.429800\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     0.3043 Validation Accuracy: 0.424400\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     0.3101 Validation Accuracy: 0.432800\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     0.2961 Validation Accuracy: 0.432600\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     0.2855 Validation Accuracy: 0.432000\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     0.2683 Validation Accuracy: 0.437200\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     0.2751 Validation Accuracy: 0.430400\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     0.2688 Validation Accuracy: 0.437000\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     0.2624 Validation Accuracy: 0.435600\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     0.2605 Validation Accuracy: 0.436200\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     0.2583 Validation Accuracy: 0.436200\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     0.2510 Validation Accuracy: 0.435200\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     0.2548 Validation Accuracy: 0.436400\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     0.2526 Validation Accuracy: 0.437600\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     0.2337 Validation Accuracy: 0.434400\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     0.2378 Validation Accuracy: 0.440000\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     0.2276 Validation Accuracy: 0.437400\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     0.2253 Validation Accuracy: 0.440800\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     0.2346 Validation Accuracy: 0.432800\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     0.2216 Validation Accuracy: 0.444600\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     0.2248 Validation Accuracy: 0.443200\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     0.2138 Validation Accuracy: 0.440000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     0.2159 Validation Accuracy: 0.443200\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     0.2065 Validation Accuracy: 0.435000\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     0.2072 Validation Accuracy: 0.439600\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     0.2106 Validation Accuracy: 0.440600\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     0.2178 Validation Accuracy: 0.444000\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     0.1970 Validation Accuracy: 0.433400\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     0.1996 Validation Accuracy: 0.433200\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     0.1939 Validation Accuracy: 0.430200\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     0.1929 Validation Accuracy: 0.437800\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     0.1861 Validation Accuracy: 0.431400\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     0.1912 Validation Accuracy: 0.427200\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     0.1916 Validation Accuracy: 0.431400\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     0.1849 Validation Accuracy: 0.430600\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     0.1756 Validation Accuracy: 0.427000\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     0.1709 Validation Accuracy: 0.434600\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     0.1788 Validation Accuracy: 0.427200\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     0.1729 Validation Accuracy: 0.424400\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     0.1916 Validation Accuracy: 0.416400\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     0.1714 Validation Accuracy: 0.426800\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     0.1629 Validation Accuracy: 0.434400\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     0.1783 Validation Accuracy: 0.421600\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     0.1746 Validation Accuracy: 0.423000\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     0.1746 Validation Accuracy: 0.414600\n",
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     0.1784 Validation Accuracy: 0.422200\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     0.1517 Validation Accuracy: 0.428400\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     0.1517 Validation Accuracy: 0.426000\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     0.1531 Validation Accuracy: 0.424600\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     0.1432 Validation Accuracy: 0.427800\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     0.1468 Validation Accuracy: 0.422000\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     0.1498 Validation Accuracy: 0.438400\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     0.1486 Validation Accuracy: 0.432000\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     0.1475 Validation Accuracy: 0.438200\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     0.1563 Validation Accuracy: 0.441000\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     0.1353 Validation Accuracy: 0.438600\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     0.1359 Validation Accuracy: 0.439600\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     0.1376 Validation Accuracy: 0.441600\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     0.1394 Validation Accuracy: 0.438600\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     0.1266 Validation Accuracy: 0.438600\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     0.1286 Validation Accuracy: 0.435200\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     0.1267 Validation Accuracy: 0.437600\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     0.1271 Validation Accuracy: 0.441800\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     0.1216 Validation Accuracy: 0.434600\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     0.1154 Validation Accuracy: 0.438000\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     0.1094 Validation Accuracy: 0.435200\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     0.1136 Validation Accuracy: 0.435800\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     0.1108 Validation Accuracy: 0.433000\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     0.1086 Validation Accuracy: 0.430600\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     0.1092 Validation Accuracy: 0.432400\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     0.1103 Validation Accuracy: 0.435200\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     0.1052 Validation Accuracy: 0.437000\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     0.1126 Validation Accuracy: 0.441400\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     0.1100 Validation Accuracy: 0.441200\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     0.1080 Validation Accuracy: 0.434800\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     0.1039 Validation Accuracy: 0.433800\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     0.1019 Validation Accuracy: 0.434000\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     0.1021 Validation Accuracy: 0.437000\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     0.0983 Validation Accuracy: 0.440200\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     0.0995 Validation Accuracy: 0.434200\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     0.1045 Validation Accuracy: 0.434600\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     0.0979 Validation Accuracy: 0.436800\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     0.1004 Validation Accuracy: 0.436200\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     0.1049 Validation Accuracy: 0.442400\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     0.1002 Validation Accuracy: 0.437200\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     0.0938 Validation Accuracy: 0.439800\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     0.0947 Validation Accuracy: 0.439800\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     0.0951 Validation Accuracy: 0.440400\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     0.0930 Validation Accuracy: 0.441800\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     0.0966 Validation Accuracy: 0.444800\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     0.0926 Validation Accuracy: 0.441800\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     0.0889 Validation Accuracy: 0.440600\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     0.0913 Validation Accuracy: 0.442600\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     0.0877 Validation Accuracy: 0.438800\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     0.0849 Validation Accuracy: 0.439600\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     0.0835 Validation Accuracy: 0.436000\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     0.0888 Validation Accuracy: 0.436000\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     0.0832 Validation Accuracy: 0.436200\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     0.0847 Validation Accuracy: 0.438000\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     0.0801 Validation Accuracy: 0.441200\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     0.0891 Validation Accuracy: 0.442000\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     0.0813 Validation Accuracy: 0.439600\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     0.0830 Validation Accuracy: 0.440400\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     0.0819 Validation Accuracy: 0.441600\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     0.0858 Validation Accuracy: 0.438600\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     0.0770 Validation Accuracy: 0.438600\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     0.0822 Validation Accuracy: 0.436600\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     0.0827 Validation Accuracy: 0.437600\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     0.0749 Validation Accuracy: 0.439800\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     0.0731 Validation Accuracy: 0.438000\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     0.0728 Validation Accuracy: 0.440800\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     0.0812 Validation Accuracy: 0.436200\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     0.0739 Validation Accuracy: 0.437200\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     0.0728 Validation Accuracy: 0.442200\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     0.0665 Validation Accuracy: 0.437200\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     0.0684 Validation Accuracy: 0.438400\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     0.0704 Validation Accuracy: 0.439000\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     0.0712 Validation Accuracy: 0.437400\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     0.0706 Validation Accuracy: 0.432800\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     0.0651 Validation Accuracy: 0.441600\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     0.0640 Validation Accuracy: 0.440200\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     0.0688 Validation Accuracy: 0.439800\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     0.0682 Validation Accuracy: 0.434200\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     0.0636 Validation Accuracy: 0.436200\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     0.0661 Validation Accuracy: 0.433600\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     0.0693 Validation Accuracy: 0.436600\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     0.0611 Validation Accuracy: 0.442000\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     0.0609 Validation Accuracy: 0.442400\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     0.0595 Validation Accuracy: 0.432400\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     0.0612 Validation Accuracy: 0.434400\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     0.0565 Validation Accuracy: 0.430800\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     0.0605 Validation Accuracy: 0.436600\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     0.0530 Validation Accuracy: 0.428400\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     0.0585 Validation Accuracy: 0.437400\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     0.0550 Validation Accuracy: 0.434400\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     0.0585 Validation Accuracy: 0.436600\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     0.0589 Validation Accuracy: 0.431200\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     0.0561 Validation Accuracy: 0.431800\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     0.0557 Validation Accuracy: 0.433800\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     0.0549 Validation Accuracy: 0.426400\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     0.0552 Validation Accuracy: 0.433000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     0.0552 Validation Accuracy: 0.429200\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     0.0510 Validation Accuracy: 0.438800\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     0.0564 Validation Accuracy: 0.430200\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     0.0572 Validation Accuracy: 0.419600\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     0.0577 Validation Accuracy: 0.426000\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     0.0550 Validation Accuracy: 0.438200\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     0.0535 Validation Accuracy: 0.431400\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     0.0599 Validation Accuracy: 0.429000\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     0.0479 Validation Accuracy: 0.432600\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     0.0533 Validation Accuracy: 0.427000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     0.0534 Validation Accuracy: 0.424400\n",
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     0.0505 Validation Accuracy: 0.430400\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     0.0485 Validation Accuracy: 0.430200\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     0.0489 Validation Accuracy: 0.419000\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     0.0504 Validation Accuracy: 0.431400\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     0.0544 Validation Accuracy: 0.420400\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     0.0544 Validation Accuracy: 0.427200\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     0.0568 Validation Accuracy: 0.415800\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     0.0491 Validation Accuracy: 0.427800\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     0.0483 Validation Accuracy: 0.420800\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     0.0481 Validation Accuracy: 0.435600\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     0.0524 Validation Accuracy: 0.420200\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     0.0482 Validation Accuracy: 0.433800\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     0.0481 Validation Accuracy: 0.425800\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     0.0456 Validation Accuracy: 0.428400\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     0.0476 Validation Accuracy: 0.427800\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     0.0613 Validation Accuracy: 0.415800\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     0.0460 Validation Accuracy: 0.424000\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     0.0504 Validation Accuracy: 0.420400\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     0.0422 Validation Accuracy: 0.431200\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     0.0512 Validation Accuracy: 0.420400\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     0.0396 Validation Accuracy: 0.430400\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     0.0401 Validation Accuracy: 0.433000\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     0.0405 Validation Accuracy: 0.430200\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     0.0423 Validation Accuracy: 0.437200\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     0.0408 Validation Accuracy: 0.436200\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     0.0380 Validation Accuracy: 0.436600\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     0.0428 Validation Accuracy: 0.439200\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     0.0466 Validation Accuracy: 0.427600\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     0.0364 Validation Accuracy: 0.433000\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     0.0404 Validation Accuracy: 0.436400\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     0.0415 Validation Accuracy: 0.437000\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     0.0391 Validation Accuracy: 0.427400\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     0.0407 Validation Accuracy: 0.438400\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     0.0388 Validation Accuracy: 0.435000\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     0.0411 Validation Accuracy: 0.431600\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     0.0377 Validation Accuracy: 0.440600\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     0.0372 Validation Accuracy: 0.434000\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     0.0430 Validation Accuracy: 0.431600\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     0.0436 Validation Accuracy: 0.438800\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     0.0351 Validation Accuracy: 0.436400\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     0.0418 Validation Accuracy: 0.439000\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     0.0378 Validation Accuracy: 0.433000\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     0.0358 Validation Accuracy: 0.434200\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     0.0387 Validation Accuracy: 0.426200\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     0.0397 Validation Accuracy: 0.429200\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     0.0353 Validation Accuracy: 0.427000\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     0.0344 Validation Accuracy: 0.425000\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     0.0322 Validation Accuracy: 0.429200\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     0.0391 Validation Accuracy: 0.424800\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     0.0426 Validation Accuracy: 0.426800\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     0.0390 Validation Accuracy: 0.422200\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     0.0394 Validation Accuracy: 0.428800\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     0.0375 Validation Accuracy: 0.426600\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     0.0341 Validation Accuracy: 0.427800\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     0.0340 Validation Accuracy: 0.424200\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     0.0321 Validation Accuracy: 0.424600\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     0.0319 Validation Accuracy: 0.429800\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     0.0319 Validation Accuracy: 0.431400\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     0.0336 Validation Accuracy: 0.419200\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     0.0398 Validation Accuracy: 0.425800\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     0.0381 Validation Accuracy: 0.423000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     0.0320 Validation Accuracy: 0.427800\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     0.0338 Validation Accuracy: 0.423200\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     0.0385 Validation Accuracy: 0.425600\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     0.0573 Validation Accuracy: 0.411400\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     0.0402 Validation Accuracy: 0.418200\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     0.0495 Validation Accuracy: 0.415200\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     0.0425 Validation Accuracy: 0.419800\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     0.0334 Validation Accuracy: 0.434200\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     0.0345 Validation Accuracy: 0.440200\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     0.0281 Validation Accuracy: 0.445600\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     0.0298 Validation Accuracy: 0.435600\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     0.0340 Validation Accuracy: 0.440800\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     0.0281 Validation Accuracy: 0.436200\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     0.0283 Validation Accuracy: 0.439000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     0.0297 Validation Accuracy: 0.435200\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     0.0288 Validation Accuracy: 0.439000\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     0.0255 Validation Accuracy: 0.441800\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     0.0239 Validation Accuracy: 0.440000\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     0.0272 Validation Accuracy: 0.441200\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     0.0225 Validation Accuracy: 0.442600\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     0.0271 Validation Accuracy: 0.436400\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     0.0204 Validation Accuracy: 0.436800\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     0.0211 Validation Accuracy: 0.435200\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     0.0223 Validation Accuracy: 0.437600\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     0.0279 Validation Accuracy: 0.444400\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     0.0234 Validation Accuracy: 0.438000\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     0.0238 Validation Accuracy: 0.439200\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     0.0243 Validation Accuracy: 0.439800\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     0.0221 Validation Accuracy: 0.438000\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     0.0236 Validation Accuracy: 0.436800\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     0.0223 Validation Accuracy: 0.440000\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     0.0241 Validation Accuracy: 0.440400\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     0.0206 Validation Accuracy: 0.437400\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     0.0200 Validation Accuracy: 0.434800\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     0.0225 Validation Accuracy: 0.438200\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     0.0191 Validation Accuracy: 0.432200\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     0.0200 Validation Accuracy: 0.436600\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     0.0200 Validation Accuracy: 0.440000\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     0.0168 Validation Accuracy: 0.437800\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     0.0204 Validation Accuracy: 0.439600\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     0.0211 Validation Accuracy: 0.444200\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     0.0190 Validation Accuracy: 0.436400\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     0.0189 Validation Accuracy: 0.434600\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     0.0216 Validation Accuracy: 0.447400\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     0.0239 Validation Accuracy: 0.443400\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     0.0196 Validation Accuracy: 0.435000\n",
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     0.0186 Validation Accuracy: 0.440600\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     0.0202 Validation Accuracy: 0.440800\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     0.0181 Validation Accuracy: 0.440400\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     0.0181 Validation Accuracy: 0.439200\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     0.0205 Validation Accuracy: 0.443400\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     0.0205 Validation Accuracy: 0.441400\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     0.0191 Validation Accuracy: 0.435600\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     0.0174 Validation Accuracy: 0.443000\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     0.0204 Validation Accuracy: 0.444400\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     0.0141 Validation Accuracy: 0.441400\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     0.0173 Validation Accuracy: 0.442800\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     0.0188 Validation Accuracy: 0.440000\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     0.0152 Validation Accuracy: 0.444800\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     0.0136 Validation Accuracy: 0.439600\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     0.0157 Validation Accuracy: 0.436000\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     0.0139 Validation Accuracy: 0.442600\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     0.0145 Validation Accuracy: 0.441000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     0.0131 Validation Accuracy: 0.447200\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     0.0157 Validation Accuracy: 0.439600\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     0.0150 Validation Accuracy: 0.439000\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     0.0145 Validation Accuracy: 0.436400\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     0.0175 Validation Accuracy: 0.443000\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     0.0168 Validation Accuracy: 0.442400\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     0.0168 Validation Accuracy: 0.444200\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     0.0177 Validation Accuracy: 0.441800\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     0.0154 Validation Accuracy: 0.443200\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     0.0127 Validation Accuracy: 0.438800\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     0.0147 Validation Accuracy: 0.439600\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     0.0152 Validation Accuracy: 0.442400\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     0.0144 Validation Accuracy: 0.439000\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     0.0167 Validation Accuracy: 0.444400\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     0.0115 Validation Accuracy: 0.441600\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     0.0118 Validation Accuracy: 0.437400\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     0.0115 Validation Accuracy: 0.448400\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     0.0134 Validation Accuracy: 0.438200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
